# Pr√≥ximos Passos - ProfWatch

## ‚úÖ O que j√° est√° rodando (Status Atual)
- [x] **Automa√ß√£o com Playwright**: Substitui√ß√£o do Selenium por Playwright, permitindo raspagem ass√≠ncrona e mais est√°vel.
- [x] **Scrapers Funcionais**: UNESP e Unicamp est√£o extraindo vagas com sucesso (testado com ~20 resultados).
- [x] **Frontend Moderno**: Interface em `/` com listagem, pagina√ß√£o, modo escuro e filtros din√¢micos.
- [x] **Backend com Cache**: `main.py` entrega resultados instant√¢neos usando cache em mem√≥ria.
- [x] **Gest√£o de Depend√™ncias**: Migra√ß√£o para `uv` conclu√≠da, facilitando a instala√ß√£o em novos ambientes.

## üöÄ Pr√≥ximos Passos (Evolu√ß√£o)
Aqui est√£o os pr√≥ximos passos recomendados para a evolu√ß√£o da ferramenta:


## 1. Refinamento dos Scrapers
- [ ] **USP**: Investigar o seletor `#inscricao-sitcon`. O site pode estar usando um iframe ou mudando IDs dinamicamente.
- [ ] **UFSCar**: Ajustar o clique no menu "Em Andamento". Verificar se a navega√ß√£o por texto puro √© est√°vel ou se seletores CSS mais espec√≠ficos s√£o necess√°rios.
- [ ] **Qualidade dos Dados**: Melhorar a extra√ß√£o da "√Årea do Conhecimento", que em alguns casos vem como `null` ou cont√©m texto extra desnecess√°rio.

## 2. Persist√™ncia de Dados
- [ ] **Banco de Dados**: Implementar o uso de **PostgreSQL** ou **SQLite** (via SQLAlchemy) para armazenar as vagas permanentemente. No momento, usamos apenas um cache em mem√≥ria.
- [ ] **Hist√≥rico**: Permitir que o usu√°rio veja vagas que j√° foram encerradas (arquivamento).
- [ ] **Diferencia√ß√£o**: Implementar l√≥gica para identificar vagas novas desde o √∫ltimo scraping e evitar duplicatas.

## 3. Melhorias no Frontend
- [ ] **Notifica√ß√µes**: Adicionar um sistema de alertas (e-mail ou Telegram) quando uma vaga em uma √°rea espec√≠fica for encontrada.
- [ ] **Favoritos**: Permitir que o usu√°rio "marque" vagas de interesse (salvo no localStorage ou no banco vinculado a um perfil).
- [ ] **Responsividade**: Refinar ainda mais a visualiza√ß√£o em dispositivos m√≥veis, talvez usando cards em vez de tabela para telas muito pequenas.

## 4. Infraestrutura e Docker
- [ ] **Dockeriza√ß√£o**: Atualizar o `Dockerfile` para incluir as depend√™ncias do Playwright de forma est√°vel.
- [ ] **Permiss√µes**: Documentar ou automatizar a corre√ß√£o de permiss√µes da `.venv` quando o projeto √© montado como volume no Docker.
- [ ] **CI/CD**: Configurar uma GitHub Action para rodar os scrapers periodicamente e validar que os seletores n√£o quebraram.

## 5. Expans√£o
- [ ] **Novas Institui√ß√µes**: Adicionar scrapers para universidades federais (ex: UFABC, UNIFESP) e institutos federais (IFSP).
- [ ] **API P√∫blica**: Documentar o endpoint `/scrape` para que outros servi√ßos possam consumir os dados limpos.
